{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 01:00:23.940965: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:23.940991: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   611857364396965889  \\\n0  614484565059596288   \n1  614746522043973632   \n2  614877582664835073   \n3  611932373039644672   \n4  611570404268883969   \n\n  @aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap  \\\n0  Dorian Gray with Rainbow Scarf #LoveWins (from...                              \n1  @SelectShowcase @Tate_StIves ... Replace with ...                              \n2  @Sofabsports thank you for following me back. ...                              \n3  @britishmuseum @TudorHistory What a beautiful ...                              \n4  @NationalGallery @ThePoldarkian I have always ...                              \n\n  nocode  \n0  happy  \n1  happy  \n2  happy  \n3  happy  \n4  happy  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>611857364396965889</th>\n      <th>@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap</th>\n      <th>nocode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>614484565059596288</td>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>614746522043973632</td>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>614877582664835073</td>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>611932373039644672</td>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>611570404268883969</td>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"annotationsfinal.csv\")\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df.columns = ['random', 'Tweet', 'Sentiment']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                   random                                            \\\n                    count          mean           std           min   \nSentiment                                                             \nangry                57.0  6.119109e+17  1.410195e+15  6.104118e+17   \ndisgust               6.0  6.130681e+17  1.715073e+15  6.107624e+17   \ndisgust|angry         7.0  6.124351e+17  1.593844e+15  6.107596e+17   \nhappy              1137.0  6.130342e+17  3.132433e+15  5.210143e+17   \nhappy|sad             9.0  6.136165e+17  1.567929e+15  6.116190e+17   \nhappy|surprise       11.0  6.130532e+17  1.567604e+15  6.105684e+17   \nnocode             1571.0  6.127426e+17  6.360210e+15  3.871909e+17   \nnot-relevant        214.0  6.127273e+17  1.424607e+15  6.083137e+17   \nsad                  32.0  6.131118e+17  1.429148e+15  6.104965e+17   \nsad|angry             2.0  6.143755e+17  1.000598e+15  6.136680e+17   \nsad|disgust           2.0  6.125822e+17  3.043721e+15  6.104299e+17   \nsad|disgust|angry     1.0  6.129109e+17           NaN  6.129109e+17   \nsurprise             35.0  6.131260e+17  1.821907e+15  6.085875e+17   \n\n                                                                           \n                            25%           50%           75%           max  \nSentiment                                                                  \nangry              6.107477e+17  6.114579e+17  6.133064e+17  6.144741e+17  \ndisgust            6.117703e+17  6.137034e+17  6.140144e+17  6.149955e+17  \ndisgust|angry      6.111874e+17  6.123081e+17  6.131752e+17  6.152529e+17  \nhappy              6.118554e+17  6.132677e+17  6.144167e+17  6.155952e+17  \nhappy|sad          6.121973e+17  6.129931e+17  6.150997e+17  6.154772e+17  \nhappy|surprise     6.120040e+17  6.126685e+17  6.144418e+17  6.152539e+17  \nnocode             6.115891e+17  6.129786e+17  6.141586e+17  6.155956e+17  \nnot-relevant       6.116094e+17  6.129711e+17  6.137050e+17  6.155779e+17  \nsad                6.118744e+17  6.130778e+17  6.144717e+17  6.151083e+17  \nsad|angry          6.140217e+17  6.143755e+17  6.147293e+17  6.150830e+17  \nsad|disgust        6.115060e+17  6.125822e+17  6.136583e+17  6.147344e+17  \nsad|disgust|angry  6.129109e+17  6.129109e+17  6.129109e+17  6.129109e+17  \nsurprise           6.115374e+17  6.133116e+17  6.146652e+17  6.155346e+17  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"8\" halign=\"left\">random</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n    <tr>\n      <th>Sentiment</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>angry</th>\n      <td>57.0</td>\n      <td>6.119109e+17</td>\n      <td>1.410195e+15</td>\n      <td>6.104118e+17</td>\n      <td>6.107477e+17</td>\n      <td>6.114579e+17</td>\n      <td>6.133064e+17</td>\n      <td>6.144741e+17</td>\n    </tr>\n    <tr>\n      <th>disgust</th>\n      <td>6.0</td>\n      <td>6.130681e+17</td>\n      <td>1.715073e+15</td>\n      <td>6.107624e+17</td>\n      <td>6.117703e+17</td>\n      <td>6.137034e+17</td>\n      <td>6.140144e+17</td>\n      <td>6.149955e+17</td>\n    </tr>\n    <tr>\n      <th>disgust|angry</th>\n      <td>7.0</td>\n      <td>6.124351e+17</td>\n      <td>1.593844e+15</td>\n      <td>6.107596e+17</td>\n      <td>6.111874e+17</td>\n      <td>6.123081e+17</td>\n      <td>6.131752e+17</td>\n      <td>6.152529e+17</td>\n    </tr>\n    <tr>\n      <th>happy</th>\n      <td>1137.0</td>\n      <td>6.130342e+17</td>\n      <td>3.132433e+15</td>\n      <td>5.210143e+17</td>\n      <td>6.118554e+17</td>\n      <td>6.132677e+17</td>\n      <td>6.144167e+17</td>\n      <td>6.155952e+17</td>\n    </tr>\n    <tr>\n      <th>happy|sad</th>\n      <td>9.0</td>\n      <td>6.136165e+17</td>\n      <td>1.567929e+15</td>\n      <td>6.116190e+17</td>\n      <td>6.121973e+17</td>\n      <td>6.129931e+17</td>\n      <td>6.150997e+17</td>\n      <td>6.154772e+17</td>\n    </tr>\n    <tr>\n      <th>happy|surprise</th>\n      <td>11.0</td>\n      <td>6.130532e+17</td>\n      <td>1.567604e+15</td>\n      <td>6.105684e+17</td>\n      <td>6.120040e+17</td>\n      <td>6.126685e+17</td>\n      <td>6.144418e+17</td>\n      <td>6.152539e+17</td>\n    </tr>\n    <tr>\n      <th>nocode</th>\n      <td>1571.0</td>\n      <td>6.127426e+17</td>\n      <td>6.360210e+15</td>\n      <td>3.871909e+17</td>\n      <td>6.115891e+17</td>\n      <td>6.129786e+17</td>\n      <td>6.141586e+17</td>\n      <td>6.155956e+17</td>\n    </tr>\n    <tr>\n      <th>not-relevant</th>\n      <td>214.0</td>\n      <td>6.127273e+17</td>\n      <td>1.424607e+15</td>\n      <td>6.083137e+17</td>\n      <td>6.116094e+17</td>\n      <td>6.129711e+17</td>\n      <td>6.137050e+17</td>\n      <td>6.155779e+17</td>\n    </tr>\n    <tr>\n      <th>sad</th>\n      <td>32.0</td>\n      <td>6.131118e+17</td>\n      <td>1.429148e+15</td>\n      <td>6.104965e+17</td>\n      <td>6.118744e+17</td>\n      <td>6.130778e+17</td>\n      <td>6.144717e+17</td>\n      <td>6.151083e+17</td>\n    </tr>\n    <tr>\n      <th>sad|angry</th>\n      <td>2.0</td>\n      <td>6.143755e+17</td>\n      <td>1.000598e+15</td>\n      <td>6.136680e+17</td>\n      <td>6.140217e+17</td>\n      <td>6.143755e+17</td>\n      <td>6.147293e+17</td>\n      <td>6.150830e+17</td>\n    </tr>\n    <tr>\n      <th>sad|disgust</th>\n      <td>2.0</td>\n      <td>6.125822e+17</td>\n      <td>3.043721e+15</td>\n      <td>6.104299e+17</td>\n      <td>6.115060e+17</td>\n      <td>6.125822e+17</td>\n      <td>6.136583e+17</td>\n      <td>6.147344e+17</td>\n    </tr>\n    <tr>\n      <th>sad|disgust|angry</th>\n      <td>1.0</td>\n      <td>6.129109e+17</td>\n      <td>NaN</td>\n      <td>6.129109e+17</td>\n      <td>6.129109e+17</td>\n      <td>6.129109e+17</td>\n      <td>6.129109e+17</td>\n      <td>6.129109e+17</td>\n    </tr>\n    <tr>\n      <th>surprise</th>\n      <td>35.0</td>\n      <td>6.131260e+17</td>\n      <td>1.821907e+15</td>\n      <td>6.085875e+17</td>\n      <td>6.115374e+17</td>\n      <td>6.133116e+17</td>\n      <td>6.146652e+17</td>\n      <td>6.155346e+17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Sentiment').describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df=df.drop(['random'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df=df[df.Sentiment!='nocode']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Tweet Sentiment\n0  Dorian Gray with Rainbow Scarf #LoveWins (from...     happy\n1  @SelectShowcase @Tate_StIves ... Replace with ...     happy\n2  @Sofabsports thank you for following me back. ...     happy\n3  @britishmuseum @TudorHistory What a beautiful ...     happy\n4  @NationalGallery @ThePoldarkian I have always ...     happy",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Tweet         \\\n                  count unique   \nSentiment                        \nangry                57     57   \ndisgust               6      6   \ndisgust|angry         7      7   \nhappy              1137   1136   \nhappy|sad             9      9   \nhappy|surprise       11     11   \nnot-relevant        214    188   \nsad                  32     32   \nsad|angry             2      2   \nsad|disgust           2      2   \nsad|disgust|angry     1      1   \nsurprise             35     35   \n\n                                                                           \n                                                                 top freq  \nSentiment                                                                  \nangry              @nationalgallery #AskTheGallery Why do you pay...    1  \ndisgust            .@NationalGallery ignores questions on sponsor...    1  \ndisgust|angry      @ReclaimOurBard @pcs_union @NationalGallery : ...    1  \nhappy              Spent the morning learning about #8mummies @br...    2  \nhappy|sad          saw Indigenous Australia exhibition @britishmu...    1  \nhappy|surprise     The most erotic painting in The @NationalGalle...    1  \nnot-relevant       @NationalGallery The 2nd GENOCIDE against #Bia...   15  \nsad                @BBC_Culture @PlymouthMuseum Oh dear, why not ...    1  \nsad|angry          @NationalGallery brought son to see Stubbs - v...    1  \nsad|disgust        If u're concerned&gt;outsourcing&amp;volunteer...    1  \nsad|disgust|angry  Stop the privatisation of services at the @Nat...    1  \nsurprise                            @britishmuseum turquoise eyes!!!    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Tweet</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>Sentiment</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>angry</th>\n      <td>57</td>\n      <td>57</td>\n      <td>@nationalgallery #AskTheGallery Why do you pay...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>disgust</th>\n      <td>6</td>\n      <td>6</td>\n      <td>.@NationalGallery ignores questions on sponsor...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>disgust|angry</th>\n      <td>7</td>\n      <td>7</td>\n      <td>@ReclaimOurBard @pcs_union @NationalGallery : ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>happy</th>\n      <td>1137</td>\n      <td>1136</td>\n      <td>Spent the morning learning about #8mummies @br...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>happy|sad</th>\n      <td>9</td>\n      <td>9</td>\n      <td>saw Indigenous Australia exhibition @britishmu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>happy|surprise</th>\n      <td>11</td>\n      <td>11</td>\n      <td>The most erotic painting in The @NationalGalle...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>not-relevant</th>\n      <td>214</td>\n      <td>188</td>\n      <td>@NationalGallery The 2nd GENOCIDE against #Bia...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>sad</th>\n      <td>32</td>\n      <td>32</td>\n      <td>@BBC_Culture @PlymouthMuseum Oh dear, why not ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>sad|angry</th>\n      <td>2</td>\n      <td>2</td>\n      <td>@NationalGallery brought son to see Stubbs - v...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>sad|disgust</th>\n      <td>2</td>\n      <td>2</td>\n      <td>If u're concerned&amp;gt;outsourcing&amp;amp;volunteer...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>sad|disgust|angry</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Stop the privatisation of services at the @Nat...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>surprise</th>\n      <td>35</td>\n      <td>35</td>\n      <td>@britishmuseum turquoise eyes!!!</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Sentiment').describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Down Sampling\n",
    "\n",
    "non_happy_df=df[df[\"Sentiment\"] != \"happy\"]\n",
    "happy_df=df[df[\"Sentiment\"] == \"happy\"].iloc[:non_happy_df.shape[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df = pd.concat([happy_df, non_happy_df])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Tweet Sentiment\n0  Dorian Gray with Rainbow Scarf #LoveWins (from...     happy\n1  @SelectShowcase @Tate_StIves ... Replace with ...     happy\n2  @Sofabsports thank you for following me back. ...     happy\n3  @britishmuseum @TudorHistory What a beautiful ...     happy\n4  @NationalGallery @ThePoldarkian I have always ...     happy",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(752, 2)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                  Tweet         \\\n                  count unique   \nSentiment                        \nangry                57     57   \ndisgust               6      6   \ndisgust|angry         7      7   \nhappy               376    376   \nhappy|sad             9      9   \nhappy|surprise       11     11   \nnot-relevant        214    188   \nsad                  32     32   \nsad|angry             2      2   \nsad|disgust           2      2   \nsad|disgust|angry     1      1   \nsurprise             35     35   \n\n                                                                           \n                                                                 top freq  \nSentiment                                                                  \nangry              @nationalgallery #AskTheGallery Why do you pay...    1  \ndisgust            .@NationalGallery ignores questions on sponsor...    1  \ndisgust|angry      @ReclaimOurBard @pcs_union @NationalGallery : ...    1  \nhappy              Dorian Gray with Rainbow Scarf #LoveWins (from...    1  \nhappy|sad          saw Indigenous Australia exhibition @britishmu...    1  \nhappy|surprise     The most erotic painting in The @NationalGalle...    1  \nnot-relevant       @NationalGallery The 2nd GENOCIDE against #Bia...   15  \nsad                @BBC_Culture @PlymouthMuseum Oh dear, why not ...    1  \nsad|angry          @NationalGallery brought son to see Stubbs - v...    1  \nsad|disgust        If u're concerned&gt;outsourcing&amp;volunteer...    1  \nsad|disgust|angry  Stop the privatisation of services at the @Nat...    1  \nsurprise                            @britishmuseum turquoise eyes!!!    1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"4\" halign=\"left\">Tweet</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th>count</th>\n      <th>unique</th>\n      <th>top</th>\n      <th>freq</th>\n    </tr>\n    <tr>\n      <th>Sentiment</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>angry</th>\n      <td>57</td>\n      <td>57</td>\n      <td>@nationalgallery #AskTheGallery Why do you pay...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>disgust</th>\n      <td>6</td>\n      <td>6</td>\n      <td>.@NationalGallery ignores questions on sponsor...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>disgust|angry</th>\n      <td>7</td>\n      <td>7</td>\n      <td>@ReclaimOurBard @pcs_union @NationalGallery : ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>happy</th>\n      <td>376</td>\n      <td>376</td>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>happy|sad</th>\n      <td>9</td>\n      <td>9</td>\n      <td>saw Indigenous Australia exhibition @britishmu...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>happy|surprise</th>\n      <td>11</td>\n      <td>11</td>\n      <td>The most erotic painting in The @NationalGalle...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>not-relevant</th>\n      <td>214</td>\n      <td>188</td>\n      <td>@NationalGallery The 2nd GENOCIDE against #Bia...</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>sad</th>\n      <td>32</td>\n      <td>32</td>\n      <td>@BBC_Culture @PlymouthMuseum Oh dear, why not ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>sad|angry</th>\n      <td>2</td>\n      <td>2</td>\n      <td>@NationalGallery brought son to see Stubbs - v...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>sad|disgust</th>\n      <td>2</td>\n      <td>2</td>\n      <td>If u're concerned&amp;gt;outsourcing&amp;amp;volunteer...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>sad|disgust|angry</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Stop the privatisation of services at the @Nat...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>surprise</th>\n      <td>35</td>\n      <td>35</td>\n      <td>@britishmuseum turquoise eyes!!!</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Sentiment').describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df['target']=encoder.fit_transform(df['Sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Tweet Sentiment  target\n0  Dorian Gray with Rainbow Scarf #LoveWins (from...     happy       3\n1  @SelectShowcase @Tate_StIves ... Replace with ...     happy       3\n2  @Sofabsports thank you for following me back. ...     happy       3\n3  @britishmuseum @TudorHistory What a beautiful ...     happy       3\n4  @NationalGallery @ThePoldarkian I have always ...     happy       3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Sentiment</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'disgust': 1, 'disgust|angry': 2, 'happy': 3, 'happy|sad': 4, 'happy|surprise': 5, 'not-relevant': 6, 'sad': 7, 'sad|angry': 8, 'sad|disgust': 9, 'sad|disgust|angry': 10, 'surprise': 11}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
    "print(le_name_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "cv=CountVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features=3000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "X=tfidf.fit_transform(df['Tweet']).toarray()\n",
    "y=df['target'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y ,test_size=0.2, random_state=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-06 01:00:28.914643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-06 01:00:28.914940: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915207: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915320: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915373: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915426: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-06 01:00:28.915488: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-06 01:00:28.915937: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-06 01:04:48.764901: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "bert_process = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
    "\n",
    "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "bert_preprocess=bert_process"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\narray([[-0.84351707, -0.51327276, -0.8884572 , ..., -0.7474888 ,\n        -0.7531474 ,  0.91964495],\n       [-0.8720837 , -0.5054399 , -0.9444668 , ..., -0.8584752 ,\n        -0.71745366,  0.8808299 ]], dtype=float32)>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_process(sentences)\n",
    "    return bert_encoder(preprocessed_text)['pooled_output']\n",
    "\n",
    "get_sentence_embeding([\n",
    "    \"500$ discount. hurry up\",\n",
    "    \"Bhavin, are you up for a volleybal game tomorrow?\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "                                               Tweet Sentiment  target\n0  Dorian Gray with Rainbow Scarf #LoveWins (from...     happy       3\n1  @SelectShowcase @Tate_StIves ... Replace with ...     happy       3\n2  @Sofabsports thank you for following me back. ...     happy       3\n3  @britishmuseum @TudorHistory What a beautiful ...     happy       3\n4  @NationalGallery @ThePoldarkian I have always ...     happy       3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet</th>\n      <th>Sentiment</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@Sofabsports thank you for following me back. ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n      <td>happy</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(12, activation='softmax', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'encoder_outputs':  109482241   ['keras_layer[0][0]',            \n",
      "                                 [(None, 128, 768),               'keras_layer[0][1]',            \n",
      "                                 (None, 128, 768),                'keras_layer[0][2]']            \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768)}                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " output (Dense)                 (None, 12)           9228        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,491,469\n",
      "Trainable params: 9,228\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text'), name='text', description=\"created by layer 'text'\"), but it was called on an input with incompatible shape (None, 3000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text'), name='text', description=\"created by layer 'text'\"), but it was called on an input with incompatible shape (None, 3000).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileob_n7c6l.py\", line 74, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.ld(self)._has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, ('result', 'training'), 1)\n    File \"/tmp/__autograph_generated_fileob_n7c6l.py\", line 72, in else_body_3\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n    File \"/tmp/__autograph_generated_fileob_n7c6l.py\", line 72, in <lambda>\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"keras_layer\" (type KerasLayer).\n    \n    in user code:\n    \n        File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n            result = smart_cond.smart_cond(training,\n    \n        ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n          Positional arguments (3 total):\n            * <tf.Tensor 'inputs:0' shape=(None, 3000) dtype=string>\n            * False\n            * None\n          Keyword arguments: {}\n        \n         Expected these arguments to match one of the following 4 option(s):\n        \n        Option 1:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 2:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * True\n            * None\n          Keyword arguments: {}\n        \n        Option 3:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 4:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * True\n            * None\n          Keyword arguments: {}\n    \n    \n    Call arguments received by layer \"keras_layer\" (type KerasLayer):\n      • inputs=tf.Tensor(shape=(None, 3000), dtype=string)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [28]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m/tmp/__autograph_generated_filebusmanou.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[1;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/tmp/__autograph_generated_fileob_n7c6l.py:74\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001B[0;34m(self, inputs, training)\u001B[0m\n\u001B[1;32m     72\u001B[0m     result \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(smart_cond)\u001B[38;5;241m.\u001B[39msmart_cond, (ag__\u001B[38;5;241m.\u001B[39mld(training), ag__\u001B[38;5;241m.\u001B[39mautograph_artifact(\u001B[38;5;28;01mlambda\u001B[39;00m : ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(f), (), \u001B[38;5;28mdict\u001B[39m(training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), fscope)), ag__\u001B[38;5;241m.\u001B[39mautograph_artifact(\u001B[38;5;28;01mlambda\u001B[39;00m : ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(f), (), \u001B[38;5;28mdict\u001B[39m(training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m), fscope))), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[1;32m     73\u001B[0m result \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mUndefined(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 74\u001B[0m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mif_stmt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_has_training_argument\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mif_body_3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43melse_body_3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_state_3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_state_3\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresult\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtraining\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state_6\u001B[39m():\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (result,)\n",
      "File \u001B[0;32m/tmp/__autograph_generated_fileob_n7c6l.py:72\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3\u001B[0;34m()\u001B[0m\n\u001B[1;32m     70\u001B[0m     training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     71\u001B[0m ag__\u001B[38;5;241m.\u001B[39mif_stmt(ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m'\u001B[39m,), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 72\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43msmart_cond\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msmart_cond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograph_artifact\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograph_artifact\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mag__\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mld\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mdict\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfscope\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/tmp/__autograph_generated_fileob_n7c6l.py:72\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3.<locals>.<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     70\u001B[0m     training \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     71\u001B[0m ag__\u001B[38;5;241m.\u001B[39mif_stmt(ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtraining\u001B[39m\u001B[38;5;124m'\u001B[39m,), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 72\u001B[0m result \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(smart_cond)\u001B[38;5;241m.\u001B[39msmart_cond, (ag__\u001B[38;5;241m.\u001B[39mld(training), ag__\u001B[38;5;241m.\u001B[39mautograph_artifact(\u001B[38;5;28;01mlambda\u001B[39;00m : ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(f), (), \u001B[38;5;28mdict\u001B[39m(training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), fscope)), ag__\u001B[38;5;241m.\u001B[39mautograph_artifact(\u001B[38;5;28;01mlambda\u001B[39;00m : ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(f), (), \u001B[38;5;28mdict\u001B[39m(training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m), fscope))), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n",
      "\u001B[0;31mValueError\u001B[0m: in user code:\n\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_fileob_n7c6l.py\", line 74, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.ld(self)._has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, ('result', 'training'), 1)\n    File \"/tmp/__autograph_generated_fileob_n7c6l.py\", line 72, in else_body_3\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n    File \"/tmp/__autograph_generated_fileob_n7c6l.py\", line 72, in <lambda>\n        result = ag__.converted_call(ag__.ld(smart_cond).smart_cond, (ag__.ld(training), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=True), fscope)), ag__.autograph_artifact(lambda : ag__.converted_call(ag__.ld(f), (), dict(training=False), fscope))), None, fscope)\n\n    ValueError: Exception encountered when calling layer \"keras_layer\" (type KerasLayer).\n    \n    in user code:\n    \n        File \"/home/rohan/miniconda3/envs/6.86x/lib/python3.10/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n            result = smart_cond.smart_cond(training,\n    \n        ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n          Positional arguments (3 total):\n            * <tf.Tensor 'inputs:0' shape=(None, 3000) dtype=string>\n            * False\n            * None\n          Keyword arguments: {}\n        \n         Expected these arguments to match one of the following 4 option(s):\n        \n        Option 1:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 2:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='sentences')\n            * True\n            * None\n          Keyword arguments: {}\n        \n        Option 3:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * False\n            * None\n          Keyword arguments: {}\n        \n        Option 4:\n          Positional arguments (3 total):\n            * TensorSpec(shape=(None,), dtype=tf.string, name='inputs')\n            * True\n            * None\n          Keyword arguments: {}\n    \n    \n    Call arguments received by layer \"keras_layer\" (type KerasLayer):\n      • inputs=tf.Tensor(shape=(None, 3000), dtype=string)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}